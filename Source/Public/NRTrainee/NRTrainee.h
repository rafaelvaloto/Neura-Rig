// Project: NeuraRig
// Copyright (c) 2026 Rafael Valoto
// All rights reserved.
#pragma once

#include "NRCore/NRTypes.h"
#include "NRInterfaces/INRModel.h"
#include <vector>

namespace NR
{
	template<FloatingPoint T = float>
	class NRTrainee
	{
		std::shared_ptr<INRModel<T> > TargetModel;
		std::unique_ptr<torch::optim::Adam> Optimizer;
		NRModelProfile RigDesc;

		/**
		 * Calculates the next rotation for a given trainee in a training schedule.
		 *
		 * @param TargetModel The current trainee's identifier.
		 * @param Rig The list of all trainees in the schedule.
		 * @param LearningRate The step or interval to determine the next trainee.
		 */
	public:
		NRTrainee(std::shared_ptr<INRModel<T> > TargetModel, NRModelProfile Rig, double LearningRate = 1e-3);

		/**
		 * Executes the next step in the training process by determining the current stage.
		 *
		 * @param InputFloats The dataset being used for the training process.
		 * @param L1_R The incremental value used to advance the training.
		 * @param L2_R The incremental value used to advance the training.
		 * @param L1_L The incremental value used to advance the training.
		 * @param L2_L The incremental value used to advance the training.
		 * @return A flag indicating whether the training step was successfully completed.
		 */
		float TrainStep(const std::vector<float>& InputFloats, float L1_R, float L2_R, float L1_L, float L2_L);

		/**
		 * Computes the Inverse Kinematics (IK) loss for a given model configuration.
		 *
		 * @param Input The predicted pose generated by the model.
		 * @param PredQuats The target pose to compare against.
		 * @param L1_R  A scaling factor applied to the loss computation.
		 * @param L2_R  A scaling factor applied to the loss computation.
		 * @param L1_L  A scaling factor applied to the loss computation.
		 * @param L2_L  A scaling factor applied to the loss computation.
		 */
		IKLossResult ComputeIKLoss(const torch::Tensor& Input, const torch::Tensor& PredQuats, float L1_R, float L2_R, float L1_L, float L2_L);

		void SaveWeights(const std::string& Path);

		void LoadWeights(const std::string& Path);


		// Normaliza quaternions: q / ||q||
		torch::Tensor NormalizeQuats(const torch::Tensor& q)
		{
			return q / (q.norm(2, /*dim=*/1, /*keepdim=*/true) + 1e-8f);
		}

		// Multiplicação de quaternions: q1 * q2 (batched)
		// q = (x, y, z, w)
		torch::Tensor QuatMultiply(const torch::Tensor& q1, const torch::Tensor& q2)
		{
			auto x1 = q1.select(1, 0), y1 = q1.select(1, 1);
			auto z1 = q1.select(1, 2), w1 = q1.select(1, 3);
			auto x2 = q2.select(1, 0), y2 = q2.select(1, 1);
			auto z2 = q2.select(1, 2), w2 = q2.select(1, 3);

			auto w = w1 * w2 - x1 * x2 - y1 * y2 - z1 * z2;
			auto x = w1 * x2 + x1 * w2 + y1 * z2 - z1 * y2;
			auto y = w1 * y2 - x1 * z2 + y1 * w2 + z1 * x2;
			auto z = w1 * z2 + x1 * y2 - y1 * x2 + z1 * w2;

			return torch::stack({x, y, z, w}, /*dim=*/1);
		}

		// Aplica rotação de um quaternion num vetor (batched)
		// q: (B, 4)  v: (B, 3)  → (B, 3)
		torch::Tensor QuatRotateVector(const torch::Tensor& q, const torch::Tensor& v)
		{
			// q = (x, y, z, w)
			auto qvec = q.slice(/*dim=*/1, 0, 3); // (B, 3) - parte xyz
			auto qw = q.slice(/*dim=*/1, 3, 4);   // (B, 1) - parte w

			// t = 2 * cross(qvec, v)
			auto t = 2.0f * torch::linalg_cross(qvec, v);

			// result = v + qw * t + cross(qvec, t)
			return v + qw * t + torch::linalg_cross(qvec, t);
		}

		FKResult ForwardKinematicsChain(
			const torch::Tensor& PelvisPos,   // (B, 3) — do input[0..2]
			const torch::Tensor& PelvisQuat,  // (B, 4) — do input[3..6]
			const torch::Tensor& ThighOffset, // (B, 3) — thigh_pos LS do input (offset do pelvis)
			float L1,                         // comprimento femur
			float L2,                         // comprimento tíbia
			const torch::Tensor& ThighQuat,   // (B, 4) — PREDITO pelo modelo
			const torch::Tensor& CalfQuat,    // (B, 4) — PREDITO pelo modelo
			const torch::Tensor& BoneAxis);    // direção do bone no espaço local

	};
} // namespace NR
